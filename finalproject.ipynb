{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFQpbVtW7kVM"
   },
   "source": [
    "# Final project - MovieLens recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NOA_Ppcf8jQd",
    "outputId": "08aaab43-4b51-4139-e8b5-ae2d58424488"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#check if GPU is working when this notebook running on Google Colab\\nimport tensorflow as tf\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n  raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#check if GPU is working when this notebook running on Google Colab\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "S_t73_iG7kVO",
    "outputId": "feb1e96b-0232-4504-e9ea-a127fca9e492"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ycr/anaconda3/envs/recsys/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "#using !pip to install libraries on Google Colab\n",
    "\n",
    "#!pip install bottleneck\n",
    "#!pip install lightfm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import lightfm\n",
    "from lightfm import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "#from tensorflow.contrib.layers import apply_regularization, l2_regularizer\n",
    "#import bottleneck as bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xxXi3QxX7kVW",
    "outputId": "6800d516-5b60-45f8-ce30-f35ba9300dd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = pd.read_csv(('Data/ml-latest/ratings.csv'), header=0)\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the original data, there are 27753444 rating events from 283228 users and 53889 movies (sparsity: 0.182%)\n"
     ]
    }
   ],
   "source": [
    "n_users = original.userId.unique().shape[0]\n",
    "n_items = original.movieId.unique().shape[0]\n",
    "sparsity = float(original.shape[0]) / float(n_users*n_items) * 100\n",
    "\n",
    "print(\"In the original data, there are %d rating events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (original.shape[0], n_users, n_items, sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KXr877eruDNZ"
   },
   "source": [
    "# FM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkyowecRuGfu"
   },
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uoHL4p7Jm1-h",
    "outputId": "0975b3e2-6716-4e77-e766-f2731e2d00e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering, there are 2775344 rating events from 237948 users and 29430 movies (sparsity: 0.040%)\n"
     ]
    }
   ],
   "source": [
    "#dataset = original.sample(frac=0.1, replace=True)   #if you want to randomly sample the original data, uncomment this line\n",
    "dataset = original  \n",
    "n_users = dataset.userId.unique().shape[0]\n",
    "n_items = dataset.movieId.unique().shape[0]\n",
    "sparsity = float(dataset.shape[0]) / float(n_users*n_items) * 100\n",
    "\n",
    "print(\"Before filtering, there are %d rating events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (dataset.shape[0], n_users, n_items, sparsity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bXUGT2Aw7kVg"
   },
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "    return count\n",
    "def filter_triplets(tp, min_uc=0, min_sc=0):\n",
    "    # Only keep the triplets for items which were rated by at least min_sc users. \n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'movieId')\n",
    "        tp = tp[tp['movieId'].isin(itemcount.index[itemcount >= min_sc])]\n",
    "    \n",
    "    # Only keep the triplets for users who rated at least min_uc items\n",
    "    # After doing this, some of the items will have less than min_uc users, but should only be a small proportion\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'userId')\n",
    "        tp = tp[tp['userId'].isin(usercount.index[usercount >= min_uc])]\n",
    "    \n",
    "    # Update both usercount and itemcount after filtering\n",
    "    usercount, itemcount = get_count(tp, 'userId'), get_count(tp, 'movieId') \n",
    "    return tp, usercount, itemcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bp2seUkyvOi5"
   },
   "source": [
    "Only keep items that are rated by at least 50 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0pBZvKarxGX"
   },
   "outputs": [],
   "source": [
    "dataset, user_fm, item_fm = filter_triplets(dataset,min_sc = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qQCr9EtKs_Qo",
    "outputId": "9206908a-6854-4bb0-b435-2fd53c6a8cd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 2608029 rating events from 236736 users and 5577 movies (sparsity: 0.198%) for lightfm\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * dataset.shape[0] / (user_fm.shape[0] * item_fm.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d rating events from %d users and %d movies (sparsity: %.3f%%) for lightfm\" % \n",
    "      (dataset.shape[0], user_fm.shape[0], item_fm.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "HmUspRlIwqEz",
    "outputId": "d284a4ac-0d6c-4941-f22c-d5aed2a9dbc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6788440</th>\n",
       "      <td>69734</td>\n",
       "      <td>780</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1279883119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26499140</th>\n",
       "      <td>270637</td>\n",
       "      <td>3468</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1168582514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18890007</th>\n",
       "      <td>192755</td>\n",
       "      <td>849</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1245532324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20368836</th>\n",
       "      <td>207751</td>\n",
       "      <td>143355</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1522181849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346770</th>\n",
       "      <td>3507</td>\n",
       "      <td>635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>855839923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating   timestamp\n",
       "6788440    69734      780     4.0  1279883119\n",
       "26499140  270637     3468     4.0  1168582514\n",
       "18890007  192755      849     2.5  1245532324\n",
       "20368836  207751   143355     3.0  1522181849\n",
       "346770      3507      635     4.0   855839923"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNSr1fDTwWyi"
   },
   "outputs": [],
   "source": [
    "def sparse_matrix(dataset):\n",
    "    movieId_to_idx = {}\n",
    "    idx_to_movieId = {}\n",
    "    for (idx, movieId) in enumerate(dataset.movieId.unique().tolist()):\n",
    "        movieId_to_idx[movieId] = idx\n",
    "        idx_to_movieId[idx] = movieId\n",
    "    \n",
    "    userId_to_idx = {}\n",
    "    idx_to_userId = {}\n",
    "    for (idx, userId) in enumerate(dataset.userId.unique().tolist()):\n",
    "        userId_to_idx[userId] = idx\n",
    "        idx_to_userId[idx] = userId\n",
    "    \n",
    "    def map_ids(row, mapper):\n",
    "        return mapper[row]\n",
    "    \n",
    "    I = dataset.userId.apply(map_ids, args=[userId_to_idx]).values\n",
    "    J = dataset.movieId.apply(map_ids, args=[movieId_to_idx]).values\n",
    "    V = np.ones(I.shape[0])\n",
    "    data = scipy.sparse.coo_matrix((V, (I, J)), dtype=np.float64)\n",
    "    data = data.tocsr()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fjiVM7VhzHHj"
   },
   "outputs": [],
   "source": [
    "data = sparse_matrix(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZH4XSTwzb53"
   },
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t52ELREgzNFh"
   },
   "outputs": [],
   "source": [
    "train, test = lightfm.cross_validation.random_train_test_split(data,0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_N6w-PFzPRr"
   },
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bc6ycxjFev5e"
   },
   "source": [
    "### evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Hnp4HemmdUk"
   },
   "outputs": [],
   "source": [
    "def ndcgatk(x_test, x_predict, k):\n",
    "    ndcg_values = []\n",
    "    total_ndcg = 0.0\n",
    "    best  = 0.0\n",
    "    for i in range(len(x_test)):\n",
    "        top_rated_movies_idx = [i for i, x in enumerate(x_test[i].tolist()) if x == 1.0]\n",
    "\n",
    "        if len(top_rated_movies_idx) == 0:\n",
    "            #print(\"test user has no 1 rated movies: \", i)\n",
    "            continue\n",
    "        sorted_ratings = x_predict[i].tolist()\n",
    "        top_predicted_movies_idx = sorted(range(len(sorted_ratings)), key=lambda i: sorted_ratings[i])[-k:]\n",
    "        sum_ndcg = 0\n",
    "        for i in range(0, k):\n",
    "            if top_predicted_movies_idx[i] in top_rated_movies_idx:\n",
    "                ndcg = 1/(math.log(i+2))\n",
    "            else:\n",
    "                dcg = 0\n",
    "            sum_ndcg += ndcg\n",
    "\n",
    "        total_ndcg += sum_ndcg\n",
    "        ndcg_values.append(sum_ndcg)\n",
    "\n",
    "    ndcg_values = np.array(ndcg_values)\n",
    "    max_ndcg = ndcg_values.max()\n",
    "    ndcg_values = ndcg_values / max_ndcg \n",
    "    total_ndcg = np.sum(ndcg_values)\n",
    "\n",
    "    return total_ndcg/float(len(ndcg_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMib7Ag4fgD6"
   },
   "outputs": [],
   "source": [
    "def recallatk(x_test, x_predict, k):\n",
    "    recall_values = []\n",
    "    total_recall = 0.0\n",
    "    for i in range(len(x_test)):\n",
    "        top_rated_movies_idx = [i for i, x in enumerate(x_test[i].tolist()) if x == 1.0]\n",
    "\n",
    "        if len(top_rated_movies_idx) == 0:\n",
    "            #print(\"test user has no 1 rated movies: \", i)\n",
    "            continue\n",
    "\n",
    "        sorted_ratings = x_predict[i].tolist()\n",
    "        top_predicted_movies_idx = sorted(range(len(sorted_ratings)), key=lambda i: sorted_ratings[i])[-k:]\n",
    "\n",
    "        sum = 0.0\n",
    "        for i in range(0, k):\n",
    "            if top_predicted_movies_idx[i] in top_rated_movies_idx:\n",
    "                sum+=1.0\n",
    "        recall = sum/float(min(k, len(top_rated_movies_idx)))\n",
    "        total_recall += recall\n",
    "        recall_values.append(recall)\n",
    "    return total_recall/float(len(recall_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wI22IZeFziVF"
   },
   "source": [
    "### without side information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhjzmI0hzXJ6"
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DKuXXOzPadeE",
    "outputId": "010261b8-e396-424e-aecc-837cc30c4871"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x1a1f3af978>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only use one epoch because of the running time\n",
    "model = LightFM(learning_rate=0.05,loss = 'warp')\n",
    "model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid = list(range(0,train.shape[0]))\n",
    "mid = list(range(0,train.shape[1]))\n",
    "predict_train = []\n",
    "for i in uid:\n",
    "    predict = model.predict(i, mid)\n",
    "    predict_train.append(predict.tolist())\n",
    "predict_train = np.array(predict_train)\n",
    "\n",
    "predict_test = []\n",
    "for i in uid:\n",
    "    predict = model.predict(i, mid)\n",
    "    predict_test.append(predict.tolist())\n",
    "predict_test = np.array(predict_test)\n",
    "\n",
    "x_train = train.toarray()\n",
    "x_test = test.toarray()\n",
    "recall_train = recallatk(x_train,predict_train,20)\n",
    "ndcg_train = ndcgatk(x_train, predict_train,100)\n",
    "recall_test = recallatk(x_test,predict_test,20)\n",
    "ndcg_test = ndcgatk(x_test, predict_test,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xmtjS5KzoNB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@20: train 0.10, test 0.09.\n",
      "NDCG@100: train 0.08, test 0.05.\n"
     ]
    }
   ],
   "source": [
    "print('Recall@20: train %.2f, test %.2f.' % (recall_train, recall_test))\n",
    "print('NDCG@100: train %.2f, test %.2f.' % (ndcg_train, ndcg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise.prediction_algorithms.knns import KNNBaseline\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection.search import GridSearchCV\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Dataset\n",
    "from surprise import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(line_format='user item rating', sep=',', skip_lines=3, rating_scale=(1, 5))\n",
    "cf_data=pd.read_csv('Data/ml-latest/ratings.csv')\n",
    "cf_data=cf_data.drop(['timestamp'],axis=1)\n",
    "cf_data, user_fm, item_fm = filter_triplets(cf_data,min_sc = 50)\n",
    "cf_data=Dataset.load_from_df(cf_data,reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x1a1db2a710>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neighbor_size=np.arange(40,100,15)\n",
    "#param_grid = {'k': neighbor_size}\n",
    "#knn=GridSearchCV(KNNBaseline,param_grid)\n",
    "#knn.fit(cf_data)\n",
    "#bestk = knn_gs.best_params['mae']['k']\n",
    "#algo=KNNBaseline(k=bestk)\n",
    "trainset, testset = train_test_split(cf_data, test_size=.2)\n",
    "algo = KNNBaseline(k=80)\n",
    "algo.fit(trainset)\n",
    "#predict_train = algo.test(trainset)\n",
    "#predict_test = algo.test(testset)\n",
    "#c_v=cross_validate(algo, cf_data,cv=10,return_train_measures =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def surprise_recall_at_k(predictions, k=10, threshold=4):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls_test_20 = surprise_recall_at_k(predict_test,20)\n",
    "recall_test_20 = sum(rec for rec in recalls_test_20.values()) / len(recalls_test_20)\n",
    "recalls_test_50 = surprise_recall_at_k(predict_test,50)\n",
    "recall_test_50 = sum(rec for rec in recalls_test_50.values()) / len(recalls_test_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@20: test 0.33.\n",
      "Recall@50: test 0.35.\n"
     ]
    }
   ],
   "source": [
    "#recall_test = recallatk(testset,predict_test,20)\n",
    "#ndcg_test = ndcgatk(testset, predict_test,100)\n",
    "print('Recall@20: test %.2f.' % (recall_test_20))\n",
    "print('Recall@50: test %.2f.' % (recall_test_50))\n",
    "#print('NDCG@100: train %.2f, test %.2f.' % (ndcg_train, ndcg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVDpp\n",
    "algo = SVDpp(lr_all = 0.011, reg_all = 0.1)\n",
    "algo.fit(trainset)\n",
    "predict_test = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@20: test 0.63.\n",
      "Recall@50: test 0.70.\n"
     ]
    }
   ],
   "source": [
    "recalls_test_20 = surprise_recall_at_k(predict_test,20)\n",
    "recall_test_20 = sum(rec for rec in recalls_test_20.values()) / len(recalls_test_20)\n",
    "recalls_test_50 = surprise_recall_at_k(predict_test,50)\n",
    "recall_test_50 = sum(rec for rec in recalls_test_50.values()) / len(recalls_test_50)\n",
    "print('Recall@20: test %.2f.' % (recall_test_20))\n",
    "print('Recall@50: test %.2f.' % (recall_test_50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AzWgkJyuAFl"
   },
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdoznVhe7kVR"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JvoZPJwR7kVS"
   },
   "source": [
    "We load the data and create train/validation/test splits following strong generalization: \n",
    "\n",
    "- We split all users into training/validation/test sets. \n",
    "\n",
    "- We train models using the entire click history of the training users. \n",
    "\n",
    "- To evaluate, we take part of the click history from held-out (validation and test) users to learn the necessary user-level representations for the model and then compute metrics by looking at how well the model ranks the rest of the unseen click history from the held-out users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iKjs_KvdnDg7"
   },
   "source": [
    "We need to binarize the data for vae.                     \n",
    "We only keep ratings >= 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LywqzdJ7kVY"
   },
   "outputs": [],
   "source": [
    "# binarize the data (only keep ratings >= 4)\n",
    "raw_data = original[original['rating'] > 3.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4fSHRfRa7kVb",
    "outputId": "29f541ee-d3cc-4441-95cf-9ec79cfc0afb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2134</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2478</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1256677239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1256677260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId  movieId  rating   timestamp\n",
       "3        1     1257     4.5  1256677460\n",
       "4        1     1449     4.5  1256677264\n",
       "7        1     2134     4.5  1256677464\n",
       "8        1     2478     4.0  1256677239\n",
       "11       1     3020     4.0  1256677260"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nBd0elm67kVf"
   },
   "source": [
    "### Data splitting procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQtBMcDB7kVf"
   },
   "source": [
    "- Select 10K users as heldout users, 10K users as validation users, and the rest of the users for training\n",
    "- Use all the items from the training users as item set\n",
    "- For each of both validation and test user, subsample 80% as fold-in data and the rest for prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PiPENPb1zDv-",
    "outputId": "0dacde19-17b3-418d-d897-9473a0dc5db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering, there are 13839395 rating events from 277240 users and 37198 movies (sparsity: 0.134%)\n"
     ]
    }
   ],
   "source": [
    "n_users = raw_data.userId.unique().shape[0]\n",
    "n_items = raw_data.movieId.unique().shape[0]\n",
    "sparsity = float(raw_data.shape[0]) / float(n_users*n_items) * 100\n",
    "\n",
    "print(\"Before filtering, there are %d rating events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
    "      (raw_data.shape[0], n_users, n_items, sparsity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8xpdYjQ7kVk"
   },
   "source": [
    "Only keep items that are rated by at least 50 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "844467Jd7kVl"
   },
   "outputs": [],
   "source": [
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data,min_sc=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0ojiptXz7kVn",
    "outputId": "2e32dcad-b883-4994-85c8-25129b6867aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering, there are 13634186 rating events from 277045 users and 9053 movies (sparsity: 0.544%) for VAE\n"
     ]
    }
   ],
   "source": [
    "sparsity = 1. * raw_data.shape[0] / (user_activity.shape[0] * item_popularity.shape[0])\n",
    "\n",
    "print(\"After filtering, there are %d rating events from %d users and %d movies (sparsity: %.3f%%) for VAE\" % \n",
    "      (raw_data.shape[0], user_activity.shape[0], item_popularity.shape[0], sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OxTYDcG7kVp"
   },
   "outputs": [],
   "source": [
    "unique_uid = user_activity.index\n",
    "\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8F4k5PYa7kVr"
   },
   "outputs": [],
   "source": [
    "# create train/validation/test users\n",
    "n_users = unique_uid.size\n",
    "n_heldout_users = 10000\n",
    "\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAJDJagb7kVt"
   },
   "outputs": [],
   "source": [
    "train_plays = raw_data.loc[raw_data['userId'].isin(tr_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvrhpaGj7kVv"
   },
   "outputs": [],
   "source": [
    "unique_sid = pd.unique(train_plays['movieId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgOt6Xwq7kVx"
   },
   "outputs": [],
   "source": [
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4PjxEYhE7kV1"
   },
   "outputs": [],
   "source": [
    "#with open(('unique_sid.txt'), 'w') as f:\n",
    " #   for sid in unique_sid:\n",
    "  #      f.write('%s\\n' % sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGSOWiE-7kV5"
   },
   "outputs": [],
   "source": [
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('userId')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for i, (_, group) in enumerate(data_grouped_by_user):\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"%d users sampled\" % i)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "    \n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmNp-YJs7kV8"
   },
   "outputs": [],
   "source": [
    "vad_plays = raw_data.loc[raw_data['userId'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "3zQUdCyA7kV-",
    "outputId": "731a617e-1c17-427f-a016-1a4f3a67c811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5QuPSeX7kWB"
   },
   "outputs": [],
   "source": [
    "test_plays = raw_data.loc[raw_data['userId'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['movieId'].isin(unique_sid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "XHcwxeUt7kWD",
    "outputId": "449bd8a5-30cf-41a0-f25b-b0ecf9f8a3a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 users sampled\n",
      "1000 users sampled\n",
      "2000 users sampled\n",
      "3000 users sampled\n",
      "4000 users sampled\n",
      "5000 users sampled\n",
      "6000 users sampled\n",
      "7000 users sampled\n",
      "8000 users sampled\n",
      "9000 users sampled\n"
     ]
    }
   ],
   "source": [
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VZnwu-a87kWF"
   },
   "source": [
    "### Save the data into (user_index, item_index) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFRmKV0g7kWF"
   },
   "outputs": [],
   "source": [
    "def numerize(tp):\n",
    "    uid = list(map(lambda x: profile2id[x], tp['userId']))\n",
    "    sid = list(map(lambda x: show2id[x], tp['movieId']))\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45WjoLMl7kWH"
   },
   "outputs": [],
   "source": [
    "train_data = numerize(train_plays)\n",
    "train_data.to_csv(('train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76zoaA5M7kWJ"
   },
   "outputs": [],
   "source": [
    "vad_data_tr = numerize(vad_plays_tr)\n",
    "vad_data_tr.to_csv(('validation_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LwDHzuEe7kWL"
   },
   "outputs": [],
   "source": [
    "vad_data_te = numerize(vad_plays_te)\n",
    "vad_data_te.to_csv(('validation_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1itrh7wd7kWN"
   },
   "outputs": [],
   "source": [
    "test_data_tr = numerize(test_plays_tr)\n",
    "test_data_tr.to_csv(('test_tr.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNWamdLw7kWO"
   },
   "outputs": [],
   "source": [
    "test_data_te = numerize(test_plays_te)\n",
    "test_data_te.to_csv(('test_te.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uTyDe8dydbWa"
   },
   "source": [
    "### get item-embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2UQTjRhedyG0"
   },
   "source": [
    "we binarize the genomes by seeting the tpo 20 genomes of each movie to 1, and the others to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jX_0oQL65OvL"
   },
   "outputs": [],
   "source": [
    "#get_genomes.py\n",
    "import json\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "NUM_GENOMES = 1128\n",
    "num_genomes = 1128\n",
    "\n",
    "#converts tuple to a 1128 dim vector\n",
    "def get_genome_vec(genome_tup):\n",
    "    vec = np.zeros(NUM_GENOMES)\n",
    "    #print len(genome_tup)\n",
    "    for i in genome_tup:\n",
    "        tag = int(i[0])-1\n",
    "        vec[tag] = 1\n",
    "    return vec\n",
    "\n",
    "\n",
    "with open('genome-scores.csv', 'r') as f:\n",
    "    genome_data = f.read().splitlines()\n",
    "\n",
    "genome_dict = {}\n",
    "\n",
    "#Collect all the genomes in genomes-scores.csv\n",
    "for i in genome_data[1:]:\n",
    "    i = i.split(\",\")\n",
    "    mid = i[0]\n",
    "    tagid = i[1]\n",
    "    relevance = float(i[2])\n",
    "    try :\n",
    "        genome_dict[mid].append((tagid, relevance))\n",
    "    except:\n",
    "        genome_dict[mid] = [(tagid, relevance)]\n",
    "        \n",
    "\n",
    "#sort and select genomes\n",
    "for mid in genome_dict.keys():\n",
    "    scores = genome_dict[mid]\n",
    "    scores = sorted(scores , key=itemgetter(1), reverse = True)\n",
    "    scores = scores[:20]\n",
    "    genome_dict[mid] = scores\n",
    "    #print len(genome_dict[mid])\n",
    "\n",
    "with open('genome_scores.json', 'w') as f:\n",
    "    json.dump(genome_dict, f)\n",
    "\n",
    "unk = np.array([0]*num_genomes)\n",
    "movie_embeddings_array = []\n",
    "\n",
    "#conv_idert list to a one hot vector\n",
    "movie_id = raw_data['movieId'].unique()\n",
    "\n",
    "for i in movie_id:\n",
    "    try:\n",
    "        movie_embeddings_array.append(get_genome_vec(genome_dict[mid]))\n",
    "    except KeyError:\n",
    "        movie_embeddings_array.append(unk)\n",
    "\n",
    "movie_embeddings_array = np.array(movie_embeddings_array)\n",
    "#with open('movie_genomes.npy', 'wb') as f:\n",
    " #   np.save(f, movie_embeddings_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jP8KNEoA7kWQ"
   },
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rjpjj5X87kWR"
   },
   "source": [
    "We define two related models: denoising autoencoder with multinomial likelihood (Multi-DAE in the paper) and partially-regularized variational autoencoder with multinomial likelihood (Multi-VAE^{PR} in the paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EPEO2LucxSUH"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1H4a2TC7kWS"
   },
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ynnANXHF7kWS"
   },
   "source": [
    "__Notations__: We use $u \\in \\{1,\\dots,U\\}$ to index users and $i \\in \\{1,\\dots,I\\}$ to index items. In this work, we consider learning with implicit feedback. The user-by-item interaction matrix is the click matrix $\\mathbf{X} \\in \\mathbb{N}^{U\\times I}$. The lower case $\\mathbf{x}_u =[X_{u1},\\dots,X_{uI}]^\\top \\in \\mathbb{N}^I$ is a bag-of-words vector with the number of clicks for each item from user u. We binarize the click matrix. It is straightforward to extend it to general count data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EyeEhwbA7kWT"
   },
   "source": [
    "__Generative process__: For each user $u$, the model starts by sampling a $K$-dimensional latent representation $\\mathbf{z}_u$ from a standard Gaussian prior. The latent representation $\\mathbf{z}_u$ is transformed via a non-linear function $f_\\theta (\\cdot) \\in \\mathbb{R}^I$ to produce a probability distribution over $I$ items $\\pi (\\mathbf{z}_u)$ from which the click history $\\mathbf{x}_u$ is assumed to have been drawn:\n",
    "\n",
    "$$\n",
    "\\mathbf{z}_u \\sim \\mathcal{N}(0, \\mathbf{I}_K),  \\pi(\\mathbf{z}_u) \\propto \\exp\\{f_\\theta (\\mathbf{z}_u\\},\\\\\n",
    "\\mathbf{x}_u \\sim \\mathrm{Mult}(N_u, \\pi(\\mathbf{z}_u))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lpFrL6dp7kWV"
   },
   "source": [
    "The objective for Multi-DAE for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\log p_\\theta(\\mathbf{x}_u | g_\\phi(\\mathbf{x}_u))\n",
    "$$\n",
    "where $g_\\phi(\\cdot)$ is the non-linear \"encoder\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p3a-roLD7kWV"
   },
   "outputs": [],
   "source": [
    "class MultiDAE(object):\n",
    "    def __init__(self, p_dims, q_dims=None, lam=0.01, lr=1e-3, random_seed=None):\n",
    "        self.p_dims = p_dims\n",
    "        if q_dims is None:\n",
    "            self.q_dims = p_dims[::-1]\n",
    "        else:\n",
    "            assert q_dims[0] == p_dims[-1], \"Input and output dimension must equal each other for autoencoders.\"\n",
    "            assert q_dims[-1] == p_dims[0], \"Latent dimension for p- and q-network mismatches.\"\n",
    "            self.q_dims = q_dims\n",
    "        self.dims = self.q_dims + self.p_dims[1:]\n",
    "        \n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        self.construct_placeholders()\n",
    "\n",
    "    def construct_placeholders(self):        \n",
    "        self.input_ph = tf.placeholder(\n",
    "            dtype=tf.float32, shape=[None, self.dims[0]])\n",
    "        self.keep_prob_ph = tf.placeholder_with_default(1.0, shape=None)\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.construct_weights()\n",
    "\n",
    "        saver, logits = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        # per-user average negative log-likelihood\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph, axis=1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        reg_var = apply_regularization(reg, self.weights)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        loss = neg_ll + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('loss', loss)\n",
    "        merged = tf.summary.merge_all()\n",
    "        return saver, logits, loss, train_op, merged\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # construct forward graph        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return tf.train.Saver(), h\n",
    "\n",
    "    def construct_weights(self):\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        # define weights\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.dims[:-1], self.dims[1:])):\n",
    "            weight_key = \"weight_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_{}\".format(i+1)\n",
    "            \n",
    "            self.weights.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZUIYYXoC7kWX"
   },
   "source": [
    "The objective of Multi-VAE^{PR} (evidence lower-bound, or ELBO) for a single user $u$ is:\n",
    "$$\n",
    "\\mathcal{L}_u(\\theta, \\phi) = \\mathbb{E}_{q_\\phi(z_u | x_u)}[\\log p_\\theta(x_u | z_u)] - \\beta \\cdot KL(q_\\phi(z_u | x_u) \\| p(z_u))\n",
    "$$\n",
    "where $q_\\phi$ is the approximating variational distribution (inference model). $\\beta$ is the additional annealing parameter that we control. The objective of the entire dataset is the average over all the users. It can be trained almost the same as Multi-DAE, thanks to reparametrization trick. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OxQGKhp7kWX"
   },
   "outputs": [],
   "source": [
    "class MultiVAE(MultiDAE):\n",
    "\n",
    "    def construct_placeholders(self):\n",
    "        super(MultiVAE, self).construct_placeholders()\n",
    "\n",
    "        # placeholders with default values when scoring\n",
    "        self.is_training_ph = tf.placeholder_with_default(0., shape=None)\n",
    "        self.anneal_ph = tf.placeholder_with_default(1., shape=None)\n",
    "        \n",
    "    def build_graph(self):\n",
    "        self._construct_weights()\n",
    "\n",
    "        saver, logits, KL = self.forward_pass()\n",
    "        log_softmax_var = tf.nn.log_softmax(logits)\n",
    "\n",
    "        neg_ll = -tf.reduce_mean(tf.reduce_sum(\n",
    "            log_softmax_var * self.input_ph,\n",
    "            axis=-1))\n",
    "        # apply regularization to weights\n",
    "        reg = l2_regularizer(self.lam)\n",
    "        \n",
    "        reg_var = apply_regularization(reg, self.weights_q + self.weights_p)\n",
    "        # tensorflow l2 regularization multiply 0.5 to the l2 norm\n",
    "        # multiply 2 so that it is back in the same scale\n",
    "        neg_ELBO = neg_ll + self.anneal_ph * KL + 2 * reg_var\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer(self.lr).minimize(neg_ELBO)\n",
    "\n",
    "        # add summary statistics\n",
    "        tf.summary.scalar('negative_multi_ll', neg_ll)\n",
    "        tf.summary.scalar('KL', KL)\n",
    "        tf.summary.scalar('neg_ELBO_train', neg_ELBO)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "        return saver, logits, neg_ELBO, train_op, merged\n",
    "    \n",
    "    def q_graph(self):\n",
    "        mu_q, std_q, KL = None, None, None\n",
    "        \n",
    "        h = tf.nn.l2_normalize(self.input_ph, 1)\n",
    "        h = tf.nn.dropout(h, self.keep_prob_ph)\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_q, self.biases_q)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_q) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "            else:\n",
    "                mu_q = h[:, :self.q_dims[-1]]\n",
    "                logvar_q = h[:, self.q_dims[-1]:]\n",
    "\n",
    "                std_q = tf.exp(0.5 * logvar_q)\n",
    "                KL = tf.reduce_mean(tf.reduce_sum(\n",
    "                        0.5 * (-logvar_q + tf.exp(logvar_q) + mu_q**2 - 1), axis=1))\n",
    "        return mu_q, std_q, KL\n",
    "\n",
    "    def p_graph(self, z):\n",
    "        h = z\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights_p, self.biases_p)):\n",
    "            h = tf.matmul(h, w) + b\n",
    "            \n",
    "            if i != len(self.weights_p) - 1:\n",
    "                h = tf.nn.tanh(h)\n",
    "        return h\n",
    "\n",
    "    def forward_pass(self):\n",
    "        # q-network\n",
    "        mu_q, std_q, KL = self.q_graph()\n",
    "        epsilon = tf.random_normal(tf.shape(std_q))\n",
    "\n",
    "        sampled_z = mu_q + self.is_training_ph *\\\n",
    "            epsilon * std_q\n",
    "\n",
    "        # p-network\n",
    "        logits = self.p_graph(sampled_z)\n",
    "        \n",
    "        return tf.train.Saver(), logits, KL\n",
    "\n",
    "    def _construct_weights(self):\n",
    "        self.weights_q, self.biases_q = [], []\n",
    "        \n",
    "        for i, (d_in, d_out) in enumerate(zip(self.q_dims[:-1], self.q_dims[1:])):\n",
    "            if i == len(self.q_dims[:-1]) - 1:\n",
    "                # we need two sets of parameters for mean and variance,\n",
    "                # respectively\n",
    "                d_out *= 2\n",
    "            weight_key = \"weight_q_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_q_{}\".format(i+1)\n",
    "            \n",
    "            self.weights_q.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_q.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_q[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_q[-1])\n",
    "            \n",
    "        self.weights_p, self.biases_p = [], []\n",
    "\n",
    "        for i, (d_in, d_out) in enumerate(zip(self.p_dims[:-1], self.p_dims[1:])):\n",
    "            weight_key = \"weight_p_{}to{}\".format(i, i+1)\n",
    "            bias_key = \"bias_p_{}\".format(i+1)\n",
    "            self.weights_p.append(tf.get_variable(\n",
    "                name=weight_key, shape=[d_in, d_out],\n",
    "                initializer=tf.contrib.layers.xavier_initializer(\n",
    "                    seed=self.random_seed)))\n",
    "            \n",
    "            self.biases_p.append(tf.get_variable(\n",
    "                name=bias_key, shape=[d_out],\n",
    "                initializer=tf.truncated_normal_initializer(\n",
    "                    stddev=0.001, seed=self.random_seed)))\n",
    "            \n",
    "            # add summary stats\n",
    "            tf.summary.histogram(weight_key, self.weights_p[-1])\n",
    "            tf.summary.histogram(bias_key, self.biases_p[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IFyg3xSn7kWZ"
   },
   "source": [
    "### Training/validation data, hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-XiPQXs7kWZ"
   },
   "source": [
    "Load the pre-processed training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7YxaIIb7kWa"
   },
   "outputs": [],
   "source": [
    "#unique_sid = list()\n",
    "#with open(('unique_sid.txt'), 'r') as f:\n",
    " #   for line in f:\n",
    "  #      unique_sid.append(line.strip())\n",
    "\n",
    "n_items = len(unique_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Pfz8ztK7kWc"
   },
   "outputs": [],
   "source": [
    "# considering deleting this cell\n",
    "def load_train_data(csv_file):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    n_users = tp['uid'].max() + 1\n",
    "\n",
    "    rows, cols = tp['uid'], tp['sid']\n",
    "    data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                             (rows, cols)), dtype='float64',\n",
    "                             shape=(n_users, n_items))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHsEidma7kWf"
   },
   "outputs": [],
   "source": [
    "#train_data = load_train_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yH0bnTNt7kWi"
   },
   "outputs": [],
   "source": [
    "#considering deleting this cell\n",
    "def load_tr_te_data(csv_file_tr, csv_file_te):\n",
    "    tp_tr = pd.read_csv(csv_file_tr)\n",
    "    tp_te = pd.read_csv(csv_file_te)\n",
    "\n",
    "    start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "    end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "    rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "    rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "    data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                             (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                             (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, n_items))\n",
    "    return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "va-FPIOZ7kWl"
   },
   "outputs": [],
   "source": [
    "#vad_data_tr, vad_data_te = load_tr_te_data(('validation_tr.csv'),\n",
    " #                                          ('validation_te.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8IJ5OfIi7kWn"
   },
   "source": [
    "Set up training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoHhdg0t7kWn"
   },
   "outputs": [],
   "source": [
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "# training batch size\n",
    "batch_size = 500\n",
    "batches_per_epoch = int(np.ceil(float(N) / batch_size))\n",
    "\n",
    "N_vad = vad_data_tr.shape[0]\n",
    "idxlist_vad = range(N_vad)\n",
    "\n",
    "# validation batch size (since the entire validation set might not fit into GPU memory)\n",
    "batch_size_vad = 2000\n",
    "\n",
    "# the total number of gradient updates for annealing\n",
    "total_anneal_steps = 200000\n",
    "# largest annealing parameter\n",
    "anneal_cap = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CENkp5du7kWr"
   },
   "source": [
    "Evaluate function: Normalized discounted cumulative gain (NDCG@k) and Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAdTeM3Y7kWr"
   },
   "outputs": [],
   "source": [
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    normalized discounted cumulative gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "    # X_pred[np.arange(batch_users)[:, np.newaxis], idx_topk] is the sorted\n",
    "    # topk predicted score\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "    # build the discount template\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRRywx587kWt"
   },
   "outputs": [],
   "source": [
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vgu7rvIS7kWx"
   },
   "source": [
    "### Train a Multi-VAE^{PR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uXV0M3I7kWx"
   },
   "source": [
    "For ML-20M dataset, we set both the generative function $f_\\theta(\\cdot)$ and the inference model $g_\\phi(\\cdot)$ to be 3-layer multilayer perceptron (MLP) with symmetrical architecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jO_21HJD7kWy"
   },
   "source": [
    "The generative function is a [200 -> 600 -> n_items] MLP, which means the inference function is a [n_items -> 600 -> 200] MLP. Thus the overall architecture for the Multi-VAE^{PR} is [n_items -> 600 -> 200 -> 600 -> n_items]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hjE2kuwe7kWz"
   },
   "outputs": [],
   "source": [
    "p_dims = [200, 600, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uLjMTouG7kW0",
    "outputId": "a892a779-4a65-4786-8895-7b2944646ec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = vae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PnNg6E8h7kW1"
   },
   "source": [
    "Set up logging and checkpoint directory\n",
    "\n",
    "- Change all the logging directory and checkpoint directory to somewhere of your choice\n",
    "- Monitor training progress using tensorflow by: `tensorboard --logdir=$log_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufU4j_oY7kW2"
   },
   "outputs": [],
   "source": [
    "#arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in vae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "e9_AHeQT7kW3",
    "outputId": "67b6b830-f6d2-447a-c0cf-5184a57bf74f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlog_dir = \\'/volmount/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}\\'.format(\\n    total_anneal_steps/1000, anneal_cap, arch_str)\\n\\nif os.path.exists(log_dir):\\n    shutil.rmtree(log_dir)\\n\\nprint(\"log directory: %s\" % log_dir)\\nsummary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "log_dir = '/volmount/log/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "vWo-eTE27kW5",
    "outputId": "a1ff1a4f-1132-40cb-819f-d9342b105fb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /volmount/chkpt/ml-20m/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NuiJs4DR7kW9"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "pHziX_mw7kW-",
    "outputId": "7e756a6d-990b-446e-baba-d945cb7c99e4"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-75745ebd1fce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mst_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mend_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_idx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mst_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;31m# [[1,2],??]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misintlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# [[1,2],j] or [[1,2],1:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mextracted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mextractor\u001b[0;34m(indices, N)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mmin_indx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmin_indx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/sparse/csr.py\u001b[0m in \u001b[0;36mcheck_bounds\u001b[0;34m(indices, N)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mmax_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_indx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index (%d) out of range'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmax_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mmin_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index (12632944) out of range"
     ]
    }
   ],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "\n",
    "    update_count = 0.0\n",
    "    \n",
    "    for epoch in range(0,n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            if total_anneal_steps > 0:\n",
    "                anneal = min(anneal_cap, 1. * update_count / total_anneal_steps)\n",
    "            else:\n",
    "                anneal = anneal_cap\n",
    "            \n",
    "            feed_dict = {vae.input_ph: X, \n",
    "                         vae.keep_prob_ph: 0.5, \n",
    "                         vae.anneal_ph: anneal,\n",
    "                         vae.is_training_ph: 1}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, \n",
    "                                           global_step=epoch * batches_per_epoch + bnum) \n",
    "            \n",
    "            update_count += 1\n",
    "        \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "drHN0wb_7kW_",
    "outputId": "bb9371de-6a15-4d86-c0f9-6fbd85139d9e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAADQCAYAAAAnI/bPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed4ebc8c18>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uMBzfzyz7kXB"
   },
   "source": [
    "### Load the test data and compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_ucl68a7kXC"
   },
   "outputs": [],
   "source": [
    "test_data_tr, test_data_te = load_tr_te_data('test_tr.csv','test_te.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vznfEAmP7kXE"
   },
   "outputs": [],
   "source": [
    "N_test = test_data_tr.shape[0]\n",
    "idxlist_test = range(N_test)\n",
    "\n",
    "batch_size_test = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-kU3TZiD7kXG",
    "outputId": "c7b73a01-65f4-4f30-d535-7d59838ab6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "vae = MultiVAE(p_dims, lam=0.0)\n",
    "saver, logits_var, _, _, _ = vae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cs3squln7kXJ"
   },
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GhRnP0mu7kXJ",
    "outputId": "1391a380-24d1-4b2f-8df4-20ebd0d48c74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /volmount/chkpt/ml-20m/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/volmount/chkpt/ml-20m/VAE_anneal{}K_cap{:1.1E}/{}'.format(\n",
    "    total_anneal_steps/1000, anneal_cap, arch_str)\n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mQ5atHob7kXL",
    "outputId": "cc1e7a6e-bcf1-4b2d-f7a4-fe7c470d27d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /volmount/chkpt/ml-20m/VAE_anneal200.0K_cap2.0E-01/I-600-200-600-I/model\n"
     ]
    }
   ],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "\n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={vae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
    "    \n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "uWHcSKjO7kXN",
    "outputId": "021b7eaa-2bec-4c9b-83c3-cffc7317221d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100=0.39521 (0.00238)\n",
      "Test Recall@20=0.40720 (0.00328)\n",
      "Test Recall@50=0.54470 (0.00336)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JVgbeSp7kXP"
   },
   "source": [
    "### Train a Multi-DAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TLIfaRwa7kXP"
   },
   "source": [
    "The generative function is a [200 -> n_items] MLP, thus the overall architecture for the Multi-DAE is [n_items -> 200 -> n_items]. We find this architecture achieves better validation NDCG@100 than the [n_items -> 600 -> 200 -> 600 -> n_items] architecture as used in Multi-VAE^{PR}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ax1WOwQd7kXQ"
   },
   "outputs": [],
   "source": [
    "p_dims = [200, n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkfa-O_L7kXS"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size, random_seed=98765)\n",
    "\n",
    "saver, logits_var, loss_var, train_op_var, merged_var = dae.build_graph()\n",
    "\n",
    "ndcg_var = tf.Variable(0.0)\n",
    "ndcg_dist_var = tf.placeholder(dtype=tf.float64, shape=None)\n",
    "ndcg_summary = tf.summary.scalar('ndcg_at_k_validation', ndcg_var)\n",
    "ndcg_dist_summary = tf.summary.histogram('ndcg_at_k_hist_validation', ndcg_dist_var)\n",
    "merged_valid = tf.summary.merge([ndcg_summary, ndcg_dist_summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j2GxdUeW7kXS"
   },
   "source": [
    "Set up logging and checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMPCplu27kXS"
   },
   "outputs": [],
   "source": [
    "arch_str = \"I-%s-I\" % ('-'.join([str(d) for d in dae.dims[1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fIAW-tLq7kXU",
    "outputId": "be5d3eaa-3488-457c-d178-4c4c549fd52e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log directory: /volmount/log/ml-20m/DAE/I-200-I\n"
     ]
    }
   ],
   "source": [
    "log_dir = '/volmount/log/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if os.path.exists(log_dir):\n",
    "    shutil.rmtree(log_dir)\n",
    "\n",
    "print(\"log directory: %s\" % log_dir)\n",
    "summary_writer = tf.summary.FileWriter(log_dir, graph=tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QKChGPwd7kXV",
    "outputId": "f4311c83-cbaf-412b-93e7-a08ec8584718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "\n",
    "if not os.path.isdir(chkpt_dir):\n",
    "    os.makedirs(chkpt_dir) \n",
    "    \n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gDqMTLko7kXX"
   },
   "outputs": [],
   "source": [
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E_Wc7teE7kXZ"
   },
   "outputs": [],
   "source": [
    "ndcgs_vad = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    best_ndcg = -np.inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        np.random.shuffle(idxlist)\n",
    "        # train for one epoch\n",
    "        for bnum, st_idx in enumerate(range(0, N, batch_size)):\n",
    "            end_idx = min(st_idx + batch_size, N)\n",
    "            X = train_data[idxlist[st_idx:end_idx]]\n",
    "            \n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')           \n",
    "            \n",
    "            feed_dict = {dae.input_ph: X, \n",
    "                         dae.keep_prob_ph: 0.5}        \n",
    "            sess.run(train_op_var, feed_dict=feed_dict)\n",
    "\n",
    "            if bnum % 100 == 0:\n",
    "                summary_train = sess.run(merged_var, feed_dict=feed_dict)\n",
    "                summary_writer.add_summary(summary_train, global_step=epoch * batches_per_epoch + bnum) \n",
    "                    \n",
    "        # compute validation NDCG\n",
    "        ndcg_dist = []\n",
    "        for bnum, st_idx in enumerate(range(0, N_vad, batch_size_vad)):\n",
    "            end_idx = min(st_idx + batch_size_vad, N_vad)\n",
    "            X = vad_data_tr[idxlist_vad[st_idx:end_idx]]\n",
    "\n",
    "            if sparse.isspmatrix(X):\n",
    "                X = X.toarray()\n",
    "            X = X.astype('float32')\n",
    "        \n",
    "            pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X} )\n",
    "            # exclude examples from training and validation (if any)\n",
    "            pred_val[X.nonzero()] = -np.inf\n",
    "            ndcg_dist.append(NDCG_binary_at_k_batch(pred_val, vad_data_te[idxlist_vad[st_idx:end_idx]]))\n",
    "        \n",
    "        ndcg_dist = np.concatenate(ndcg_dist)\n",
    "        ndcg_ = ndcg_dist.mean()\n",
    "        ndcgs_vad.append(ndcg_)\n",
    "        merged_valid_val = sess.run(merged_valid, feed_dict={ndcg_var: ndcg_, ndcg_dist_var: ndcg_dist})\n",
    "        summary_writer.add_summary(merged_valid_val, epoch)\n",
    "\n",
    "        # update the best model (if necessary)\n",
    "        if ndcg_ > best_ndcg:\n",
    "            saver.save(sess, '{}/model'.format(chkpt_dir))\n",
    "            best_ndcg = ndcg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "Fp3vacEY7kXb",
    "outputId": "80859cea-c9e4-4fcc-8e1f-b909b6af62cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAADQCAYAAAAnI/bPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fed4dc39dd8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(ndcgs_vad)\n",
    "plt.ylabel(\"Validation NDCG@100\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYew3odC7kXd"
   },
   "source": [
    "### Compute test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiOZswVw7kXd"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dae = MultiDAE(p_dims, lam=0.01 / batch_size)\n",
    "saver, logits_var, _, _, _ = dae.build_graph()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z2q5Xux07kXf"
   },
   "source": [
    "Load the best performing model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dTXKeQxb7kXg",
    "outputId": "961f1619-8e2f-41a6-e3b2-8f99375f4bad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkpt directory: /volmount/chkpt/ml-20m/DAE/I-200-I\n"
     ]
    }
   ],
   "source": [
    "chkpt_dir = '/volmount/chkpt/ml-20m/DAE/{}'.format(arch_str)\n",
    "print(\"chkpt directory: %s\" % chkpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2AP2An9_7kXh",
    "outputId": "f760dd96-76b3-4786-c833-300246f10087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /volmount/chkpt/ml-20m/DAE/I-200-I/model\n"
     ]
    }
   ],
   "source": [
    "n100_list, r20_list, r50_list = [], [], []\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    saver.restore(sess, '{}/model'.format(chkpt_dir))\n",
    "    \n",
    "    for bnum, st_idx in enumerate(range(0, N_test, batch_size_test)):\n",
    "        end_idx = min(st_idx + batch_size_test, N_test)\n",
    "        X = test_data_tr[idxlist_test[st_idx:end_idx]]\n",
    "\n",
    "        if sparse.isspmatrix(X):\n",
    "            X = X.toarray()\n",
    "        X = X.astype('float32')\n",
    "\n",
    "        pred_val = sess.run(logits_var, feed_dict={dae.input_ph: X})\n",
    "        # exclude examples from training and validation (if any)\n",
    "        pred_val[X.nonzero()] = -np.inf\n",
    "        n100_list.append(NDCG_binary_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=100))\n",
    "        r20_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=20))\n",
    "        r50_list.append(Recall_at_k_batch(pred_val, test_data_te[idxlist_test[st_idx:end_idx]], k=50))\n",
    "\n",
    "n100_list = np.concatenate(n100_list)\n",
    "r20_list = np.concatenate(r20_list)\n",
    "r50_list = np.concatenate(r50_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "PUCjU7TK7kXj",
    "outputId": "2e5b49c8-2cb6-4edb-b18f-15a67ff4c033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG@100=0.38771 (0.00238)\n",
      "Test Recall@20=0.39666 (0.00325)\n",
      "Test Recall@50=0.53241 (0.00337)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test NDCG@100=%.5f (%.5f)\" % (np.mean(n100_list), np.std(n100_list) / np.sqrt(len(n100_list))))\n",
    "print(\"Test Recall@20=%.5f (%.5f)\" % (np.mean(r20_list), np.std(r20_list) / np.sqrt(len(r20_list))))\n",
    "print(\"Test Recall@50=%.5f (%.5f)\" % (np.mean(r50_list), np.std(r50_list) / np.sqrt(len(r50_list))))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "i1H4a2TC7kWS",
    "IFyg3xSn7kWZ",
    "uMBzfzyz7kXB",
    "_JVgbeSp7kXP"
   ],
   "name": "VAE_ML20M_WWW2018.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python (recsys)",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
